# -*- coding: utf-8 -*-
"""23-03 Myopathy final version ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xBVL_XYB_5t90iXFldxFss2SC9cIGOL3
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import learning_curve, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from imblearn.over_sampling import SMOTE

# Carregando o dataset
df = pd.read_csv('df.csv')

# Substituindo valores inválidos por NaN e convertendo todas as colunas para numérico
df.replace('#VALUE!', np.nan, inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')


# Removendo colunas 'Delta' e 'PacienteID', conforme instruções
df.drop(columns=[col for col in df.columns if 'Delta' in col or col == 'PacienteID'], inplace=True)


# Preenchendo valores ausentes com a mediana das colunas
df.fillna(df.median(), inplace=True)

# Selecionando as colunas de interesse, incluindo as novas colunas mencionadas
columns_of_interest = ['Maior_Cpk', 'Menor_Cpk', 'Maior_Lactato', 'Menor_Lactato',
                       'Dor_Presente', 'Mialgia_Status', 'Mialgia_Inicial_Tipo', 'Mialgia_Atual_Tipo',
                       'Fadiga_Status', 'Caibra_Status']
df = df[columns_of_interest + ['Diagnostico_Tipo']]

# Definindo as variáveis de características (X) e o alvo (y)
X = df.drop('Diagnostico_Tipo', axis=1)
y = df['Diagnostico_Tipo']

# Dividindo os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Padronizando as características
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Aplicando SMOTE aos dados de treinamento
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

# Inicializando o classificador Random Forest e ajustando aos dados balanceados pelo SMOTE
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_smote, y_train_smote)

# Realizando predições no conjunto de teste
y_pred = rf_model.predict(X_test_scaled)

# Gerando a matriz de confusão com os rótulos corretos
cm = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Estrutural', 'Metabólico', 'Distrofia Miotônica'])

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Predições do modelo no conjunto de teste
y_pred = rf_model.predict(X_test_scaled)

# Métricas do modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print("Acurácia do modelo:", accuracy)
print("Precisão do modelo:", precision)
print("Recall do modelo:", recall)
print("F1-Score do modelo:", f1)

# Relatório de classificação para cada classe
class_report = classification_report(y_test, y_pred, target_names=['Estrutural', 'Metabólico', 'Distrofia Miotônica'])
print("\nRelatório de classificação:\n", class_report)

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import learning_curve, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, classification_report
from imblearn.over_sampling import SMOTE

# Load the dataset
df = pd.read_csv('df.csv')

# Replace #VALUE! by NaN to manage missing values and convert all columns to numeric
df.replace('#VALUE!', np.nan, inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')
df = df.dropna(subset=['Diagnostico_Tipo'])
df = df[df['Diagnostico_Tipo'] != 3]

# Drop the Delta columns as per instructions
df.drop(columns=[col for col in df.columns if 'Delta' in col], inplace=True)

# Remove the 'PacienteID' column as it's not relevant to the analysis
df.drop(columns=['PacienteID'], inplace=True)

# Fill missing values with median of the columns
df.fillna(df.median(), inplace=True)

# Select only the relevant columns for CPK, Lactato, and the new variables added
columns_of_interest = [
    'Maior_Cpk', 'Menor_Cpk', 'Maior_Lactato', 'Menor_Lactato', 'Dor_Presente', 'Mialgia_Status',
    'Mialgia_Inicial_Tipo', 'Mialgia_Atual_Tipo', 'Fadiga_Status', 'Caibra_Status'
]
df = df[columns_of_interest + ['Diagnostico_Tipo']]

# Define the features and target variable
X = df.drop('Diagnostico_Tipo', axis=1)
y = df['Diagnostico_Tipo']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Apply SMOTE to the training data
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

# Initialize a random forest classifier and fit it to the SMOTE'd data
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_smote, y_train_smote)

# Predictions using the new model
y_pred = rf_model.predict(X_test_scaled)

# Metrics for the new model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
class_report = classification_report(y_test, y_pred, target_names=['Estrutural', 'Metabólico', 'Distrofia Miotônica'])
class_report

# Convertendo o relatório de classificação em um DataFrame para uma visualização mais formatada
class_report_df = pd.DataFrame(classification_report(y_test, y_pred, target_names=['Estrutural', 'Metabólico', 'Distrofia Miotônica'], output_dict=True)).transpose()

# Exibindo as métricas
print(f"Acurácia: {accuracy:.4f}")
print(f"Precisão: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("\nRelatório de Classificação:")
print(class_report_df)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve

# Supondo que 'rf_model' é seu modelo e 'X_train_smote', 'y_train_smote' são seus dados de treino balanceados
train_sizes, train_scores, test_scores = learning_curve(
    estimator=rf_model,
    X=X_train_smote,
    y=y_train_smote,
    train_sizes=np.linspace(0.1, 1.0, 10),
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

# Calculando as médias e os desvios padrão das pontuações de treino e teste
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

# Gerando o gráfico
plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training accuracy')
plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')
plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s', markersize=5, label='Validation accuracy')
plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')

plt.title('Learning Curve')
plt.xlabel('Training Data Size')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.grid()

plt.show()

import matplotlib.pyplot as plt
import pandas as pd

# Supondo que 'rf_model' é o seu modelo Random Forest e 'X_train' são seus dados de treino

# Obtendo a importância das características
feature_importances = rf_model.feature_importances_

# Criando um DataFrame para facilitar a visualização
features_df = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': feature_importances
}).sort_values(by='Importance', ascending=False)

# Gerando o gráfico de barras para as importâncias das características
plt.figure(figsize=(10, 8))
plt.barh(features_df['Feature'], features_df['Importance'], color='skyblue')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importances')
plt.gca().invert_yaxis()  # Inverter o eixo y para mostrar a característica mais importante no topo
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Supondo que 'y_test' são os rótulos verdadeiros e 'y_pred' são as predições do seu modelo

# Calculando a matriz de confusão
cm = confusion_matrix(y_test, y_pred, labels=rf_model.classes_)

# Exibindo a matriz de confusão com rótulos
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Structural', 'Metabolic', 'Myotonic Dystrophy'])
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

diagnosis_labels = {1: 'Structural', 2: 'Metabolic', 3: 'Myotonic Dystrophy'}
plt.figure(figsize=(10, 6))
(diagnosis_freq.rename(index=diagnosis_labels)
                  .plot(kind='bar', color='slategray'))
plt.title('Diagnosis Frequency in Myopathy Cases', fontsize=16, pad=20)
plt.xlabel('Diagnosis Type', fontsize=14, labelpad=10)
plt.ylabel('Number of Cases', fontsize=14, labelpad=10)
plt.xticks(rotation=0, fontsize=12)
plt.yticks(fontsize=12)
plt.tight_layout()
plt.show()

"""# Teste removendo o grupo distrofia miotônica"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import learning_curve, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, classification_report
from imblearn.over_sampling import SMOTE

# Load the dataset
df = pd.read_csv('df.csv')

# Replace #VALUE! by NaN to manage missing values and convert all columns to numeric
df.replace('#VALUE!', np.nan, inplace=True)
df = df.apply(pd.to_numeric, errors='coerce')

# Remove rows where Diagnostico_Tipo is equal to 3 (distrofia miotonica)
df = df[df['Diagnostico_Tipo'] != 3]

# Drop the Delta columns as per instructions
df.drop(columns=[col for col in df.columns if 'Delta' in col], inplace=True)

# Remove the 'PacienteID' column as it's not relevant to the analysis
df.drop(columns=['PacienteID'], inplace=True)

# Fill missing values with median of the columns
df.fillna(df.median(), inplace=True)

# Select only the relevant columns for CPK, Lactato, and the new variables added
columns_of_interest = [
    'Maior_Cpk', 'Menor_Cpk', 'Maior_Lactato', 'Menor_Lactato',
    'Dor_Presente', 'Mialgia_Status', 'Mialgia_Inicial_Tipo', 'Mialgia_Atual_Tipo',
    'Fadiga_Status', 'Caibra_Status'
]
df = df[columns_of_interest + ['Diagnostico_Tipo']]

# Define the features and target variable
X = df.drop('Diagnostico_Tipo', axis=1)
y = df['Diagnostico_Tipo']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Apply SMOTE to the training data
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)

# Initialize a random forest classifier and fit it to the SMOTE'd data
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_smote, y_train_smote)

# Predictions using the new model
y_pred = rf_model.predict(X_test_scaled)

# Compute and print evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')

print("Acurácia do modelo:", accuracy)
print("Precisão do modelo:", precision)
print("Recall do modelo:", recall)
print("F1-Score do modelo:", f1)

# Classification report for each class
class_report = classification_report(y_test, y_pred, target_names=['Estrutural', 'Metabólico'])
print("\nRelatório de classificação:\n", class_report)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Display confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Estrutural', 'Metabólico'])
disp.plot(cmap='Blues')
plt.show()

import seaborn as sns

# Assuming rf_model and X are already defined

importances = rf_model.feature_importances_

# Sort feature importances in descending order
indices = np.argsort(importances)[::-1]

# Create a mapping for the label changes
label_mapping = {
    'Mialgia_Inicial_Tipo': 'Mialgia_Inicial_Caracteristica',
    'Mialgia_Atual_Tipo': 'Mialgia_Atual_Caracteristica'
}

# Rearrange feature names so they match the sorted feature importances
feature_names = [X.columns[i] for i in indices]

# Apply the label mapping
feature_names = [label_mapping.get(name, name) for name in feature_names]

# Create a DataFrame for Seaborn
import pandas as pd
df = pd.DataFrame({'Feature': feature_names, 'Importance': importances[indices]})

# Set the style and color palette
sns.set_style("whitegrid")
sns.set_palette("Blues_r")

# Create plot
plt.figure(figsize=(12, 6))
ax = sns.barplot(x='Importance', y='Feature', data=df)

# Add value labels to the bars
for i, v in enumerate(df['Importance']):
    ax.text(v, i, f'{v:.3f}', va='center')

# Customize the plot
plt.title("Feature Importance", fontsize=16)
plt.xlabel("Importance", fontsize=12)
plt.ylabel("Features", fontsize=12)

# Add a short legend
top_features = df['Feature'].head(3).tolist()
legend_labels = [f"{name} ({i+1})" for i, name in enumerate(top_features)]
plt.legend(legend_labels, title="Top 3 Features", loc='lower right')

plt.tight_layout()
plt.show()

from sklearn.model_selection import learning_curve

# Compute learning curve
train_sizes, train_scores, test_scores = learning_curve(rf_model, X_train_smote, y_train_smote, cv=5, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.1, 1.0, 10))

# Calculate mean and standard deviation for training and testing scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

# Plot learning curve
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, label='Training score', color='blue', marker='o')
plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')
plt.plot(train_sizes, test_mean, label='Cross-validation score', color='green', linestyle='--', marker='s')
plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')
plt.title('Learning Curve')
plt.xlabel('Training data size')
plt.ylabel('Accuracy')
plt.grid()
plt.legend(loc='lower right')
plt.show()

# Check for missing values
print("Missing values per column:")
print(df.isnull().sum())

# Summary statistics
print("\nSummary statistics:")
print(df.describe())

# Class distribution
print("\nClass distribution:")
print(df['Diagnostico_Tipo'].value_counts())

# Correlation matrix
print("\nCorrelation matrix:")
print(df.corr())

"""## Calculadora Teste"""

def predict_myopathy_type(maior_cpk, menor_cpk, maior_lactato, menor_lactato, dor_presente,
                          mialgia_status, mialgia_inicial_tipo, mialgia_atual_tipo,
                          fadiga_status, caibra_status):
    # Criar um DataFrame com os valores fornecidos
    patient_data = pd.DataFrame({
        'Maior_Cpk': [maior_cpk],
        'Menor_Cpk': [menor_cpk],
        'Maior_Lactato': [maior_lactato],
        'Menor_Lactato': [menor_lactato],
        'Dor_Presente': [dor_presente],
        'Mialgia_Status': [mialgia_status],
        'Mialgia_Inicial_Tipo': [mialgia_inicial_tipo],
        'Mialgia_Atual_Tipo': [mialgia_atual_tipo],
        'Fadiga_Status': [fadiga_status],
        'Caibra_Status': [caibra_status]
    })

    # Padronizar os dados do paciente
    patient_data_scaled = scaler.transform(patient_data)

    # Fazer a previsão usando o modelo treinado
    prediction = rf_model.predict(patient_data_scaled)

    # Mapear o valor numérico da previsão para o tipo de miopatia correspondente
    myopathy_type = 'Estrutural' if prediction[0] == 1 else 'Metabólico'

    return myopathy_type

# Exemplo de uso da função
maior_cpk = float(input("Digite o valor de Maior_Cpk: "))
menor_cpk = float(input("Digite o valor de Menor_Cpk: "))
maior_lactato = float(input("Digite o valor de Maior_Lactato: "))
menor_lactato = float(input("Digite o valor de Menor_Lactato: "))
dor_presente = int(input("Digite o valor de Dor_Presente: "))
mialgia_status = int(input("Digite o valor de Mialgia_Status: "))
mialgia_inicial_tipo = int(input("Digite o valor de Mialgia_Inicial_Tipo: "))
mialgia_atual_tipo = int(input("Digite o valor de Mialgia_Atual_Tipo: "))
fadiga_status = int(input("Digite o valor de Fadiga_Status: "))
caibra_status = int(input("Digite o valor de Caibra_Status: "))

predicted_myopathy_type = predict_myopathy_type(maior_cpk, menor_cpk, maior_lactato, menor_lactato,
                                                dor_presente, mialgia_status, mialgia_inicial_tipo,
                                                mialgia_atual_tipo, fadiga_status, caibra_status)

print("O tipo de miopatia previsto para o paciente é:", predicted_myopathy_type)

import pandas as pd

# Assume we have the rf_model and scaler already defined and loaded

def predict_myopathy_type(maior_cpk, menor_cpk, maior_lactato, menor_lactato, dor_presente,
                          mialgia_status, mialgia_inicial_tipo, mialgia_atual_tipo,
                          fadiga_status, caibra_status):
    patient_data = pd.DataFrame({
        'Maior_Cpk': [maior_cpk],
        'Menor_Cpk': [menor_cpk],
        'Maior_Lactato': [maior_lactato],
        'Menor_Lactato': [menor_lactato],
        'Dor_Presente': [dor_presente],
        'Mialgia_Status': [mialgia_status],
        'Mialgia_Inicial_Tipo': [mialgia_inicial_tipo],
        'Mialgia_Atual_Tipo': [mialgia_atual_tipo],
        'Fadiga_Status': [fadiga_status],
        'Caibra_Status': [caibra_status]
    })

    patient_data_scaled = scaler.transform(patient_data)
    prediction = rf_model.predict(patient_data_scaled)
    myopathy_type = 'Structural' if prediction[0] == 1 else 'Metabolic'
    return myopathy_type

# Patient data from previous extraction
patient_data = pd.DataFrame({
    'PacienteID': ['1059244C', '0918764F', '0695881I', '0237910D', '1019473K', '0917539A', '0154825J'],
    'Maior_Cpk': [327, 4425, 2202, 80, 52, 570, 89],
    'Menor_Cpk': [91.54, 874.76, 223, 50, 40, 334, 89],
    'Maior_Lactato': [5.2, 2.4, 3.5, 3.6, 4.5, 3.1, 2.5],
    'Menor_Lactato': [1.2, 1.41, 1.2, 1.8, 1.2, 1.4, 1.8],
    'Dor_Presente': [1, 1, 1, 1, 1, 1, 1],
    'Mialgia_Status': [1, 1, 1, 1, 1, 1, 1],
    'Mialgia_Inicial_Tipo': [5, 5, 5, 5, 5, 5, 5],
    'Mialgia_Atual_Tipo': [3, 4, 3, 3, 5, 3, 5],
    'Fadiga_Status': [1, 1, 2, 1, 1, 2, 2],
    'Caibra_Status': [1, 1, 2, 1, 1, 1, 1]
})

# Final diagnoses
final_diagnoses = [
    "DYSTROPHY WITH PSEUDOMETABOLIC MANIFESTATION",
    "DYSTROPHY WITH PSEUDOMETABOLIC MANIFESTATION",
    "TOXIC statin",
    "TOXIC STATIN",
    "TOXIC statin and hypothyroidism",
    "TOXIC statin and hypothyroidism",
    "TOXIC FIBRATE"
]

# Create the result table
result_table = []
for i, (_, row) in enumerate(patient_data.iterrows()):
    case_number = i + 1
    final_diagnosis = final_diagnoses[i]
    model_result = predict_myopathy_type(
        row['Maior_Cpk'], row['Menor_Cpk'], row['Maior_Lactato'], row['Menor_Lactato'],
        row['Dor_Presente'], row['Mialgia_Status'], row['Mialgia_Inicial_Tipo'],
        row['Mialgia_Atual_Tipo'], row['Fadiga_Status'], row['Caibra_Status']
    )
    result_table.append({
        'Case': f"Case_{case_number}",
        'Final Diagnosis': final_diagnosis,
        'Result from model': model_result,
        'Max CPK': row['Maior_Cpk'],
        'Min CPK': row['Menor_Cpk'],
        'Max Lactate': row['Maior_Lactato'],
        'Min Lactate': row['Menor_Lactato']
    })

# Convert to DataFrame for better display
result_df = pd.DataFrame(result_table)

# Display the table
print(result_df.to_string(index=False))